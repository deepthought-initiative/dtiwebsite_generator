{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### This notebook consist of code for creating the html files for the website each time data is updated."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set-up"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "from pathlib import Path\n",
                "import glob\n",
                "import numpy as np\n",
                "import shutil\n",
                "import pandas as pd\n",
                "from jinja2 import Environment, FileSystemLoader\n",
                "from jinja2.exceptions import UndefinedError"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def delete_ds_store(path):\n",
                "\n",
                "    ds_store_files = glob.glob(os.path.join(path, '**', '.DS_Store'), recursive=True)\n",
                "    \n",
                "\n",
                "    for file_path in ds_store_files:\n",
                "        os.remove(file_path)\n",
                "        print(f\"Deleted: {file_path}\")\n",
                "        \n",
                "\n",
                "current_directory = os.getcwd()\n",
                "\n",
                "\n",
                "delete_ds_store(current_directory)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Defining Constants"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Defining Paths\n",
                "GROUP_DATA_DIR = Path(\"../../group-data\")\n",
                "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"dtiwebsite_generator\" / \"templates\"\n",
                "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
                "HOSTING_PATH = GROUP_DATA_DIR.parent / \"deepthought-initiative.github.io\"\n",
                "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
                "MEMBERS_DIR = GROUP_DATA_DIR / \"members\"\n",
                "SUB_RESEARCH_PATH = HOSTING_PATH / \"sub_research\"\n",
                "\n",
                "INSTITUTION_FILTER = \"Michigan State University\"\n",
                "GROUP_FILTER = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
                "INDIVIDUAL_MEMBER_SECTION_MAP = {\n",
                "    \"education\": \"Education\",\n",
                "    \"experiences\": \"Experience\",\n",
                "    \"projects\": \"Projects\",\n",
                "    \"awards\": \"Awards & Recognition\",\n",
                "    \"outreach\": \"Outreach Programs\",\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Copying people directories\n",
                "\n",
                "# def copy_folders(source, destination):\n",
                "#     try:\n",
                "#         shutil.copytree(source, destination)\n",
                "#         print(\"Folders copied successfully!\")\n",
                "#     except shutil.Error as e:\n",
                "#         print(f\"Error copying folders: {e}\")\n",
                "#     except OSError as e:\n",
                "#         print(f\"Error creating destination directory: {e}\")\n",
                "\n",
                "# source_dir = \"../temp/group-data/members\"\n",
                "# destination_dir = \"../group-data/members\"\n",
                "\n",
                "# for folder_name in os.listdir(source_dir):\n",
                "#     folder_path = os.path.join(source_dir, folder_name)\n",
                "#     if os.path.isdir(folder_path):\n",
                "#         json_path = os.path.join(folder_path, \"jsons\", \"basic_info.json\")\n",
                "#         if os.path.exists(json_path):\n",
                "#             with open(json_path) as f:\n",
                "#                 data = json.load(f)\n",
                "#                 display_info = data.get(\"display\", {})\n",
                "#                 if display_info.get(\"dti\", True):\n",
                "#                     destination_folder = os.path.join(destination_dir, folder_name)\n",
                "#                     copy_folders(folder_path, destination_folder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Copying common article content\n",
                "# source_folder = '../temp/group-data/website_data'\n",
                "# destination_folder = '../group-data/website_data'\n",
                "\n",
                "# def copy_json_files(source_folder, destination_folder):\n",
                "#     source_content_folder = os.path.join(source_folder, 'content')\n",
                "#     destination_content_folder = os.path.join(destination_folder, 'content')\n",
                "#     destination_website_files_folder = os.path.join(destination_folder, 'website_files')\n",
                "\n",
                "#     os.makedirs(destination_content_folder, exist_ok=True)\n",
                "#     os.makedirs(destination_website_files_folder, exist_ok=True)\n",
                "\n",
                "#     for filename in os.listdir(source_content_folder):\n",
                "#         if filename.endswith('.json'):\n",
                "#             file_path = os.path.join(source_content_folder, filename)\n",
                "#             with open(file_path, 'r') as file:\n",
                "#                 try:\n",
                "#                     json_data = json.load(file)\n",
                "#                     platforms = json_data.get('platforms')\n",
                "#                     if platforms and 'dti' in platforms:\n",
                "#                         destination_path = os.path.join(destination_content_folder, filename)\n",
                "#                         shutil.copy(file_path, destination_path)\n",
                "#                         print(f\"Copied file: {filename} from '{source_content_folder}' to '{destination_content_folder}'\")\n",
                "\n",
                "#                         process_cover_image(json_data, source_folder, destination_website_files_folder)\n",
                "#                         process_content_images(json_data, source_folder, destination_website_files_folder)\n",
                "\n",
                "#                 except json.JSONDecodeError:\n",
                "#                     print(f\"Error decoding JSON in file: {file_path}\")\n",
                "\n",
                "# def process_cover_image(json_data, source_folder, destination_website_files_folder):\n",
                "#     cover_image_path = json_data.get('cover_image')\n",
                "#     if cover_image_path:\n",
                "#         source_image_path = os.path.join(source_folder, cover_image_path)\n",
                "#         if os.path.exists(source_image_path):\n",
                "#             destination_image_path = os.path.join(destination_website_files_folder, 'images', 'article_content', os.path.basename(cover_image_path))\n",
                "#             os.makedirs(os.path.dirname(destination_image_path), exist_ok=True)\n",
                "#             shutil.copy(source_image_path, destination_image_path)\n",
                "#             print(f\"Copied file: {cover_image_path} from '{source_folder}' to '{destination_image_path}'\")\n",
                "\n",
                "# def process_content_images(json_data, source_folder, destination_website_files_folder):\n",
                "#     content = json_data.get('content')\n",
                "#     if content:\n",
                "#         for key, value in content.items():\n",
                "#             if key.startswith('img'):\n",
                "#                 image_path = value\n",
                "#                 if image_path:\n",
                "#                     source_image_path = os.path.join(source_folder, image_path)\n",
                "#                     if os.path.exists(source_image_path):\n",
                "#                         destination_image_path = os.path.join(destination_website_files_folder, 'images', 'article_content', os.path.basename(image_path))\n",
                "#                         os.makedirs(os.path.dirname(destination_image_path), exist_ok=True)\n",
                "#                         shutil.copy(source_image_path, destination_image_path)\n",
                "#                         print(f\"Copied file: {image_path} from '{source_folder}' to '{destination_image_path}'\")\n",
                "\n",
                "# copy_json_files(source_folder, destination_folder)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Setting up jinja environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "def page_link(a):\n",
                "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
                "    return a.replace(\" \", \"_\") if \" \" in a else a\n",
                "\n",
                "environment = Environment(\n",
                "    loader=FileSystemLoader(TEMPLATE_DIR_PATH),\n",
                "    extensions=[\"jinja2.ext.loopcontrols\", \"jinja2.ext.do\"],\n",
                ")\n",
                "environment.globals[\"page_link\"] = page_link"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_page(template, html, **kwargs):\n",
                "    \"\"\"\n",
                "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
                "\n",
                "    Parameters:\n",
                "    ----------\n",
                "    template : str\n",
                "        The filename of the Jinja2 template to be used.\n",
                "    html : str\n",
                "        The filename of the HTML file to be generated.\n",
                "    **kwargs : dict\n",
                "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
                "\n",
                "    Returns:\n",
                "    -------\n",
                "    None\n",
                "\n",
                "    \"\"\"\n",
                "    page_template = environment.get_template(template)\n",
                "    template_level = html.count(\"/\")\n",
                "    page_html_path = HOSTING_PATH / html\n",
                "    page_content = page_template.render(TEMPLATE_LEVEL=template_level, **kwargs)\n",
                "    with open(page_html_path, mode=\"w\", encoding=\"utf-8\") as page:\n",
                "        page.write(page_content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loading_website_data(file_to_load):\n",
                "    \"\"\"\n",
                "    Load data from JSON files specified in a list of file names.\n",
                "\n",
                "    Parameters:\n",
                "    ----------\n",
                "    json_data_list : list of str\n",
                "        A list of file names (without extension) to load as JSON.\n",
                "\n",
                "    Returns:\n",
                "    -------\n",
                "    dict\n",
                "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
                "\n",
                "    Raises:\n",
                "    ------\n",
                "    FileNotFoundError:\n",
                "        If a specified file does not exist.\n",
                "    json.JSONDecodeError:\n",
                "        If there's an issue decoding the JSON content from a file.\n",
                "\n",
                "    \"\"\"\n",
                "    loaded_data = {}\n",
                "    file_matches = WEBSITE_DATA_PATH/ f\"{file_to_load}.json\"\n",
                "    print(os.path.abspath(file_matches))\n",
                "    if file_matches:\n",
                "        try:\n",
                "            with open(file_matches, \"r\") as json_file:\n",
                "                loaded_data = json.load(json_file)\n",
                "        except json.JSONDecodeError:\n",
                "            print(f\"Error decoding JSON in '{file_matches}'.\")\n",
                "    else:\n",
                "        print(f\"File '{file_to_load}.json' not found.\")\n",
                "\n",
                "    return loaded_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "def read_member_data_jsons(file_to_read):\n",
                "    data_list = []\n",
                "    for single_member_file_path in MEMBERS_DIR.rglob(f\"{file_to_read}\"):\n",
                "        with open(single_member_file_path, \"r\") as fname:\n",
                "            member_data = json.load(fname)\n",
                "        info_json_file_path = single_member_file_path.parent.parent / \"info.json\"\n",
                "        with open(info_json_file_path, \"r\") as file_info:\n",
                "            member_info_data = json.load(file_info)\n",
                "        mem_id = member_info_data[\"id\"]\n",
                "        for single_entry in member_data:\n",
                "            single_entry[\"id\"] = mem_id\n",
                "            data_list.append(single_entry)\n",
                "    if len(data_list) == 0:\n",
                "        member_data_df = pd.DataFrame()\n",
                "    else:\n",
                "        member_data_df = pd.DataFrame(data_list)\n",
                "        member_data_df.set_index(\"id\", inplace=True)\n",
                "    return member_data_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reading data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/home/abhinav/workspace/code/tardis-main/dti-website/group-data/website_data/general.json\n",
                        "/home/abhinav/workspace/code/tardis-main/dti-website/group-data/website_data/homepage.json\n",
                        "/home/abhinav/workspace/code/tardis-main/dti-website/group-data/website_data/contact.json\n",
                        "/home/abhinav/workspace/code/tardis-main/dti-website/group-data/website_data/research.json\n",
                        "/home/abhinav/workspace/code/tardis-main/dti-website/group-data/website_data/support.json\n"
                    ]
                }
            ],
            "source": [
                "# Reading website data\n",
                "general = loading_website_data(\"general\")\n",
                "homepage = loading_website_data(\"homepage\")\n",
                "contact = loading_website_data(\"contact\")\n",
                "research = loading_website_data(\"research\")\n",
                "support = loading_website_data(\"support\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reading all articles\n",
                "article_content_list = []\n",
                "for content_file_name in CONTENT_DIR_PATH.iterdir():\n",
                "    with open(content_file_name, \"r\") as fcontent:\n",
                "        article_content = json.load(fcontent)\n",
                "    article_content_list.append(article_content)\n",
                "article_content_df = pd.DataFrame(article_content_list)\n",
                "\n",
                "article_content_df[\"date\"] = pd.to_datetime(\n",
                "    article_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Categorizing news and research articles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "news_content_df = article_content_df[\n",
                "    (article_content_df[\"category\"] == \"News\")\n",
                "    | (\n",
                "        article_content_df[\"tags\"].apply(\n",
                "            lambda x: \"news\" in x if isinstance(x, list) else False\n",
                "        )\n",
                "    )\n",
                "].sort_values(by=[\"date\"], ascending=[False])\n",
                "\n",
                "research_content_df = article_content_df[\n",
                "    article_content_df[\"category\"] != \"News\"\n",
                "].sort_values(by=[\"category\", \"date\"], ascending=[True, False])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Reading personal member data from info.json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "info_json_list = []\n",
                "for single_info_file_path in MEMBERS_DIR.glob(\"*/info.json\"):\n",
                "    with open(single_info_file_path, 'r') as f_info:\n",
                "        member_data = json.load(f_info)\n",
                "    info_json_list.append(member_data)\n",
                "info_json_df = pd.DataFrame(info_json_list) \n",
                "info_json_df.set_index(\"id\", inplace=True)\n",
                "info_json_df[\"full_name\"] = info_json_df.apply(\n",
                "    lambda row: (\n",
                "        row[\"nick_name\"] + \" \" + row[\"last_name\"]\n",
                "        if pd.notna(row[\"nick_name\"])\n",
                "        else row[\"first_name\"] + \" \" + row[\"last_name\"]\n",
                "    ),\n",
                "    axis=1,\n",
                ")\n",
                "info_json_dict = info_json_df.to_dict(\"index\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Reading various json files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "exp_df = read_member_data_jsons(\"experiences.json\")[\n",
                "    [\n",
                "        \"role\",\n",
                "        \"start_date\",\n",
                "        \"end_date\",\n",
                "        \"institution\",\n",
                "        \"group\",\n",
                "    ]\n",
                "]\n",
                "edu_df = read_member_data_jsons(\"education.json\")[\n",
                "    [\"start_date\", \"end_date\", \"institution\", \"subject\", \"degree\"]\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Reading social_links json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [],
            "source": [
                "social_link_list = []\n",
                "for single_member_file_path in MEMBERS_DIR.rglob(\"social_links.json\"):\n",
                "    with open(single_member_file_path, \"r\") as fname:\n",
                "        member_social_link = json.load(fname)\n",
                "    info_json_file_path = single_member_file_path.parent.parent / \"info.json\"\n",
                "    with open(info_json_file_path, \"r\") as file_info:\n",
                "        member_info_data = json.load(file_info)\n",
                "    mem_id = member_info_data[\"id\"]\n",
                "    member_social_link[\"id\"] = mem_id\n",
                "    social_link_list.append(member_social_link)\n",
                "social_links_df = pd.DataFrame(social_link_list)\n",
                "social_links_df.set_index(\"id\", inplace=True)\n",
                "social_links_df.fillna(\"\", inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Homepage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [],
            "source": [
                "recent_content = article_content_df.sort_values(\n",
                "    by=[\"category\", \"date\"], ascending=[True, False]\n",
                ")\n",
                "# Get the first row for each category using groupby and head\n",
                "recent_content = recent_content.groupby(\"category\").head(1).copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\n",
                "    \"homepage.html.j2\",\n",
                "    \"index.html\",\n",
                "    general=general,\n",
                "    homepage=homepage,\n",
                "    recent_content=recent_content.to_dict(orient=\"records\"),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Support Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\"support.html.j2\", \"Support.html\", general=general, support=support)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Contact Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\"contact.html.j2\", \"Contact.html\", general=general, contact=contact)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## News Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\n",
                "    \"news.html.j2\",\n",
                "    \"News.html\",\n",
                "    general=general,\n",
                "    content=news_content_df,\n",
                "    category=\"news\",\n",
                "    member_data=info_json_dict,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Individual News Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": [
                "for ind_news_keys, ind_news_values in news_content_df.iterrows():\n",
                "    folder_path = HOSTING_PATH / \"news\" / page_link(ind_news_values.article_id.lower())\n",
                "    create_page(\n",
                "        \"news_page_no_twitter.html.j2\",\n",
                "        f\"news/{page_link(ind_news_values.article_id.lower())}.html\",\n",
                "        general=general,\n",
                "        content=ind_news_values,\n",
                "        member_data=info_json_dict,\n",
                "        category=\"News\",\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Research Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\n",
                "    \"computational_metascience.html.j2\",\n",
                "    \"computational_metascience.html\",\n",
                "    general=general,\n",
                "    content=research_content_df,\n",
                "    current_members=info_json_dict,\n",
                "    research=research,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sub-Research Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [],
            "source": [
                "SUB_RESEARCH_PATH.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "for category in article_content_df.loc[\n",
                "    article_content_df.category != \"News\", \"category\"\n",
                "].unique():\n",
                "    create_page(\n",
                "        \"sub_research_frontpage.html.j2\",\n",
                "        f\"sub_research/{page_link(category.lower())}.html\",\n",
                "        general=general,\n",
                "        research=research,\n",
                "        content=research_content_df,\n",
                "        category=category,\n",
                "        current_members=info_json_dict,\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Individual Research Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": [
                "for ind_research_keys, ind_research_values in research_content_df.iterrows():\n",
                "    destination_research_path = f\"sub_research/{page_link(ind_research_values.category.lower())}/{page_link(ind_research_values.article_id.lower())}.html\"\n",
                "    if ind_research_values['category'] == \"Software\":\n",
                "        destination_research_path = f\"sub_research/{page_link(ind_research_values.article_id.lower())}.html\"\n",
                "\n",
                "    folder_path = SUB_RESEARCH_PATH / page_link(ind_research_values.category.lower())\n",
                "    folder_path.mkdir(parents=True, exist_ok=True)\n",
                "    create_page(\n",
                "        \"research_page_no_twitter.html.j2\",\n",
                "        destination_research_path,\n",
                "        general=general,\n",
                "        content=ind_research_values,\n",
                "        member_data=info_json_df.to_dict(\"index\"),\n",
                "        article_id=ind_research_values[\"article_id\"],\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Current members Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "filtered_exp_df = exp_df[exp_df[\"end_date\"].isna()]\n",
                "def most_recent_row(group):\n",
                "    return group[group[\"start_date\"] == group[\"start_date\"].max()]\n",
                "filtered_exp_df_most_recent = (\n",
                "    filtered_exp_df.groupby(\"id\").apply(most_recent_row).droplevel(0)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [],
            "source": [
                "filtered_edu_df = edu_df[(edu_df[\"end_date\"].isna()) & (edu_df[\"institution\"] == INSTITUTION_FILTER)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [],
            "source": [
                "exp_ids = filtered_exp_df_most_recent.index.unique()\n",
                "edu_ids = filtered_edu_df.index.unique()\n",
                "common_ids = list(set(exp_ids).union(edu_ids))\n",
                "current_member_df = info_json_df.loc[common_ids]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m_key, m_value in current_member_df.iterrows():\n",
                "    if m_key in filtered_edu_df.index:\n",
                "        if (\n",
                "            filtered_edu_df.loc[m_key, \"degree\"] == \"Bachelors\"\n",
                "            and filtered_edu_df.loc[m_key, \"institution\"] == INSTITUTION_FILTER\n",
                "        ):\n",
                "            current_academic_role = \"Undergraduate Student\"\n",
                "        if filtered_edu_df.loc[m_key, \"degree\"] in [\"PhD\", \"Masters\"]:\n",
                "            current_academic_role = \"Graduate Student\"\n",
                "    elif m_key in filtered_exp_df_most_recent.index:\n",
                "        current_academic_role = filtered_exp_df_most_recent.loc[m_key, \"role\"]\n",
                "    else:\n",
                "        current_academic_role = \"\"\n",
                "    current_member_df.loc[m_key,\"academic_role\"] = current_academic_role"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [],
            "source": [
                "projects_df = read_member_data_jsons(\"projects.json\").sort_values(\n",
                "    by=[\"end_date\"], ascending=False\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "for mem_key, mem_value in current_member_df.iterrows():\n",
                "    if mem_key in projects_df.index:\n",
                "        mem_projects = projects_df.loc[mem_key]\n",
                "        if not mem_projects.empty:\n",
                "            if isinstance(mem_projects, pd.Series):\n",
                "                current_project_title = mem_projects[\"project_title\"]\n",
                "            else:\n",
                "                current_project_title = mem_projects.iloc[0][\"project_title\"]\n",
                "    else:\n",
                "        current_project_title = \"\"\n",
                "    current_member_df.loc[mem_key, \"current_project_title\"] = current_project_title"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\n",
                "    \"current_members.html.j2\",\n",
                "    \"current_members.html\",\n",
                "    general=general,\n",
                "    current_members=current_member_df.to_dict(\"index\"),\n",
                "    socials=social_links_df.to_dict(\"index\"),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alumni Members Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [],
            "source": [
                "def most_recent_row_end_date(group):\n",
                "    return group[group[\"end_date\"] == group[\"end_date\"].max()]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": [
                "alumni_filtered_edu_df = edu_df[edu_df[\"end_date\"].notna()]\n",
                "req_edu_df = alumni_filtered_edu_df.loc[\n",
                "    alumni_filtered_edu_df[\"institution\"] == INSTITUTION_FILTER\n",
                "]\n",
                "req_edu_df_most_recent = req_edu_df.groupby(\"id\").apply(most_recent_row_end_date).droplevel(0)\n",
                "\n",
                "\n",
                "alumni_filtered_exp_df = exp_df[exp_df[\"end_date\"].notna()]\n",
                "req_exp_df = alumni_filtered_exp_df.loc[\n",
                "    (alumni_filtered_exp_df[\"institution\"] == INSTITUTION_FILTER)\n",
                "    | (alumni_filtered_exp_df[\"group\"].isin(GROUP_FILTER))\n",
                "]\n",
                "req_exp_df_most_recent = (\n",
                "    req_exp_df.groupby(\"id\").apply(most_recent_row_end_date).droplevel(0)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": [
                "alumni_exp_ids = req_exp_df_most_recent.index.unique()\n",
                "alumni_edu_ids = req_edu_df_most_recent.index.unique()\n",
                "alumni_common_ids = list(set(alumni_exp_ids).union(alumni_edu_ids))\n",
                "alumni_member_df = info_json_df.loc[alumni_common_ids]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the indices of duplicates using set intersection\n",
                "duplicate_indices = set(current_member_df.index) & set(alumni_member_df.index)\n",
                "\n",
                "# Drop duplicates from alumni_members_df based on the indices\n",
                "alumni_member_df.drop(duplicate_indices, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m_key, m_value in alumni_member_df.iterrows():\n",
                "    if m_key in req_edu_df_most_recent.index:\n",
                "        if (\n",
                "            req_edu_df_most_recent.loc[m_key, \"degree\"] == \"Bachelors\"\n",
                "            and req_edu_df_most_recent.loc[m_key, \"institution\"] == INSTITUTION_FILTER\n",
                "        ):\n",
                "            current_academic_role = \"Undergraduate Student\"\n",
                "        if req_edu_df_most_recent.loc[m_key, \"degree\"] in [\"PhD\", \"Masters\"]:\n",
                "            current_academic_role = \"Graduate Student\"\n",
                "    elif m_key in req_exp_df_most_recent.index:\n",
                "        current_academic_role = req_exp_df_most_recent.loc[m_key, \"role\"]\n",
                "    else:\n",
                "        current_academic_role = \" \"\n",
                "    alumni_member_df.loc[m_key, \"academic_role\"] = str(current_academic_role)\n",
                "alumni_member_df['academic_role'] = alumni_member_df['academic_role'].fillna(\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_page(\n",
                "    \"alumni_members.html.j2\",\n",
                "    \"alumni_members.html\",\n",
                "    general=general,\n",
                "    alumni_members=alumni_member_df.to_dict(\"index\"),\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Individual People Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "def group_df(df):\n",
                "    new_df = (df.groupby(\"id\")\n",
                "    .apply(lambda x: x.to_dict(orient=\"records\"))\n",
                "    .reset_index(name=\"info\")\n",
                "    .set_index(\"id\")\n",
                "    .to_dict(orient=\"index\"))\n",
                "    return new_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": [
                "document_df = read_member_data_jsons(\"documents.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [],
            "source": [
                "outreach_df = read_member_data_jsons(\"outreach.json\")\n",
                "if not outreach_df.empty:\n",
                "    outreach_grouped = group_df(outreach_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [],
            "source": [
                "awards_df = read_member_data_jsons(\"awards.json\")\n",
                "awards_grouped = group_df(awards_df)\n",
                "\n",
                "exp_grouped = group_df(exp_df)\n",
                "edu_grouped = group_df(edu_df)\n",
                "projects_grouped = group_df(projects_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [],
            "source": [
                "for member_id, member_data in info_json_df.iterrows():\n",
                "    if member_id in current_member_df.index:\n",
                "        info_json_df.at[member_id, \"academic_role\"] = current_member_df.loc[\n",
                "            member_id, \"academic_role\"\n",
                "        ]\n",
                "        info_json_df.at[member_id, \"current_project_title\"] = current_member_df.loc[\n",
                "            member_id, \"current_project_title\"\n",
                "        ]\n",
                "    elif member_id in alumni_member_df.index:\n",
                "        info_json_df.at[member_id, \"academic_role\"] = alumni_member_df.loc[\n",
                "            member_id, \"academic_role\"\n",
                "        ]\n",
                "alumni_member_df.replace(\"nan\", np.nan, inplace=True)\n",
                "alumni_member_df.fillna(\"\", inplace=True)\n",
                "current_member_df.fillna(\"\", inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {},
            "outputs": [],
            "source": [
                "for person_id, person_data in info_json_df.iterrows():\n",
                "    create_page(\n",
                "        \"individual_person.html.j2\",\n",
                "        f\"members/{person_id}/{person_id}.html\",\n",
                "        general=general,\n",
                "        member_id=person_id,\n",
                "        member_data=person_data,\n",
                "        socials=social_links_df.to_dict(\"index\"),\n",
                "        documents=document_df.to_dict(\"index\"),\n",
                "        education=edu_grouped,\n",
                "        experience=exp_grouped,\n",
                "        projects=projects_grouped,\n",
                "        awards=awards_grouped,\n",
                "        outreach=outreach_df,\n",
                "        section_headings=INDIVIDUAL_MEMBER_SECTION_MAP,\n",
                "        content=article_content_df.to_dict(\"index\"),\n",
                "    )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}